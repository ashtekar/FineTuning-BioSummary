{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simple ETL Pipeline for DPO Training Data\n",
        "\n",
        "This notebook implements a straightforward ETL process to prepare preference data for OpenAI DPO fine-tuning.\n",
        "\n",
        "## Process Overview\n",
        "1. **Extract** data from `feedback_comparisons` table\n",
        "2. **Transform** HTML to text and apply preference logic\n",
        "3. **Load** into new `dpo_training_data` table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import json\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Data processing\n",
        "from bs4 import BeautifulSoup\n",
        "import html\n",
        "\n",
        "# Database\n",
        "from supabase import create_client, Client\n",
        "\n",
        "# Environment\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('.env.local')\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize Supabase Connection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Supabase client initialized successfully\n"
          ]
        }
      ],
      "source": [
        "# Initialize Supabase client\n",
        "def initialize_supabase():\n",
        "    \"\"\"Initialize Supabase client using environment variables\"\"\"\n",
        "    url = os.getenv(\"NEXT_PUBLIC_SUPABASE_URL\")\n",
        "    key = os.getenv(\"SUPABASE_SERVICE_ROLE_KEY\")\n",
        "    \n",
        "    if not url or not key:\n",
        "        raise ValueError(\"Missing Supabase credentials in .env.local\")\n",
        "    \n",
        "    supabase: Client = create_client(url, key)\n",
        "    return supabase\n",
        "\n",
        "# Initialize connection\n",
        "try:\n",
        "    supabase = initialize_supabase()\n",
        "    print(\"‚úÖ Supabase client initialized successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing Supabase: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. HTML Cleaning Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ HTML cleaning test:\n",
            "  Original: <p>This is a <strong>test</strong> with <em>HTML</em> content.</p>\n",
            "  Cleaned:  This is a test with HTML content.\n"
          ]
        }
      ],
      "source": [
        "# HTML cleaning function (Option A: Simple Strip)\n",
        "def clean_html(content):\n",
        "    \"\"\"\n",
        "    Clean HTML content using simple strip approach\n",
        "    \n",
        "    Args:\n",
        "        content: HTML content string\n",
        "    \n",
        "    Returns:\n",
        "        Cleaned plain text\n",
        "    \"\"\"\n",
        "    if not content:\n",
        "        return \"\"\n",
        "    \n",
        "    try:\n",
        "        # Decode HTML entities (&amp; ‚Üí &, &lt; ‚Üí <, etc.)\n",
        "        decoded = html.unescape(str(content))\n",
        "        \n",
        "        # Remove all HTML tags using BeautifulSoup\n",
        "        soup = BeautifulSoup(decoded, 'html.parser')\n",
        "        \n",
        "        # Get plain text and clean up whitespace\n",
        "        clean_text = soup.get_text().strip()\n",
        "        \n",
        "        return clean_text\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error cleaning HTML: {e}\")\n",
        "        return str(content)  # Return original if cleaning fails\n",
        "\n",
        "# Test the HTML cleaning function\n",
        "test_html = \"<p>This is a <strong>test</strong> with <em>HTML</em> content.</p>\"\n",
        "cleaned = clean_html(test_html)\n",
        "print(f\"‚úÖ HTML cleaning test:\")\n",
        "print(f\"  Original: {test_html}\")\n",
        "print(f\"  Cleaned:  {cleaned}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create DPO Training Data Table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ dpo_training_data table is accessible and ready\n"
          ]
        }
      ],
      "source": [
        "# Verify dpo_training_data table is accessible\n",
        "def verify_dpo_table():\n",
        "    \"\"\"Verify that the dpo_training_data table is accessible\"\"\"\n",
        "    \n",
        "    try:\n",
        "        # Try to query the table to verify it exists and is accessible\n",
        "        response = supabase.table('dpo_training_data').select('uuid').limit(1).execute()\n",
        "        print(\"‚úÖ dpo_training_data table is accessible and ready\")\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error accessing dpo_training_data table: {e}\")\n",
        "        print(\"Please ensure the table exists in your Supabase database\")\n",
        "        return False\n",
        "\n",
        "# Verify the table\n",
        "table_ready = verify_dpo_table()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Extract Data from feedback_comparisons\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Extracted 50 total records\n",
            "‚ö†Ô∏è Skipped record - missing required fields\n",
            "‚ö†Ô∏è Skipped record - missing required fields\n",
            "‚ö†Ô∏è Skipped record - missing required fields\n",
            "‚ö†Ô∏è Skipped record - missing required fields\n",
            "‚úÖ 46 valid records after filtering\n",
            "‚ö†Ô∏è 4 records skipped\n",
            "\n",
            "üìù Sample record structure:\n",
            "  id: 9e57bad2-75fd-4e1e-b35c-7cf5daeae67f\n",
            "  session_id: 0748b433-dcfc-42d0-bca2-05c5650331d7\n",
            "  recipient_id: c2f3f6cf-658e-4602-972b-1105ae245df5\n",
            "  summary_id: 2bead982-11c5-42a6-9c70-08391a63296c\n",
            "  article_id: 9d820575-fcd3-4523-b097-9b393815c245\n",
            "  current_summary: <!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            "<head>\n",
            "    <meta charset=\"UTF-8\">\n",
            "    <meta name=\"viewport\" content...\n",
            "  advanced_summary: <div>\n",
            "  <p><strong>How to create state-of-the-art genetic model systems: strategies for ‚Ä¶</strong></...\n",
            "  current_model: gpt-4o-mini\n",
            "  advanced_model: gpt-5\n",
            "  user_preference: B\n",
            "  comparison_order: 1\n",
            "  extraction_method: generated\n",
            "  created_at: 2025-08-28T00:03:34.433573+00:00\n"
          ]
        }
      ],
      "source": [
        "# Extract data from feedback_comparisons with filtering\n",
        "def extract_feedback_data():\n",
        "    \"\"\"\n",
        "    Extract data from feedback_comparisons table with basic filtering\n",
        "    \n",
        "    Returns:\n",
        "        List of valid feedback records\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Query feedback_comparisons with basic filtering\n",
        "        response = supabase.table('feedback_comparisons').select('*').execute()\n",
        "        \n",
        "        if not response.data:\n",
        "            print(\"‚ö†Ô∏è No data found in feedback_comparisons table\")\n",
        "            return []\n",
        "        \n",
        "        print(f\"üìä Extracted {len(response.data)} total records\")\n",
        "        \n",
        "        # Apply filtering logic\n",
        "        filtered_records = []\n",
        "        skipped_count = 0\n",
        "        \n",
        "        for record in response.data:\n",
        "            # Check required fields\n",
        "            if (record.get('user_preference') and \n",
        "                record.get('current_summary') and \n",
        "                record.get('advanced_summary') and \n",
        "                record.get('article_id')):\n",
        "                \n",
        "                # Check preference is valid\n",
        "                if record['user_preference'] in ['A', 'B']:\n",
        "                    filtered_records.append(record)\n",
        "                else:\n",
        "                    skipped_count += 1\n",
        "                    print(f\"‚ö†Ô∏è Skipped record - invalid preference: {record.get('user_preference')}\")\n",
        "            else:\n",
        "                skipped_count += 1\n",
        "                print(f\"‚ö†Ô∏è Skipped record - missing required fields\")\n",
        "        \n",
        "        print(f\"‚úÖ {len(filtered_records)} valid records after filtering\")\n",
        "        print(f\"‚ö†Ô∏è {skipped_count} records skipped\")\n",
        "        \n",
        "        return filtered_records\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error extracting data: {e}\")\n",
        "        return []\n",
        "\n",
        "# Extract the data\n",
        "feedback_data = extract_feedback_data()\n",
        "\n",
        "# Show sample record structure\n",
        "if feedback_data:\n",
        "    print(f\"\\nüìù Sample record structure:\")\n",
        "    sample_record = feedback_data[0]\n",
        "    for key, value in sample_record.items():\n",
        "        print(f\"  {key}: {str(value)[:100]}{'...' if len(str(value)) > 100 else ''}\")\n",
        "else:\n",
        "    print(\"‚ùå No valid data extracted\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Transform Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Transforming feedback data...\n",
            "‚úÖ Transformed 46 records successfully\n",
            "\n",
            "üìù Sample transformed record:\n",
            "  uuid: 8e99580f-45ee-432d-93c2-55200a6a67f4\n",
            "  input_message: Jun 28, 2018 ... Engineering CRISPR/Cpf1 with tRNA promotes genome ... molecules enhance CRISPR/Cas9... (length: 160)\n",
            "  preferred_output: How to create state-of-the-art genetic model systems: strategies for ‚Ä¶\n",
            "This article outlines practic...\n",
            "  non_preferred_output: Summary of Synthetic Biology Article\n",
            "\n",
            "\n",
            "Summary of \"How to create state-of-the-art genetic model syst...\n"
          ]
        }
      ],
      "source": [
        "# Transform data: Clean HTML and apply preference logic\n",
        "def get_article_content(article_id):\n",
        "    \"\"\"Get article content by article_id\"\"\"\n",
        "    try:\n",
        "        response = supabase.table('articles').select('content').eq('id', article_id).execute()\n",
        "        if response.data:\n",
        "            return response.data[0]['content']\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Article not found for ID: {article_id}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error fetching article {article_id}: {e}\")\n",
        "        return None\n",
        "\n",
        "def transform_feedback_data(feedback_records):\n",
        "    \"\"\"\n",
        "    Transform feedback data into DPO training format\n",
        "    \n",
        "    Args:\n",
        "        feedback_records: List of feedback comparison records\n",
        "    \n",
        "    Returns:\n",
        "        List of transformed DPO training records\n",
        "    \"\"\"\n",
        "    transformed_records = []\n",
        "    errors = []\n",
        "    \n",
        "    for i, record in enumerate(feedback_records):\n",
        "        try:\n",
        "            # Get article content\n",
        "            article_content = get_article_content(record['article_id'])\n",
        "            if not article_content:\n",
        "                errors.append(f\"Record {i}: Article not found\")\n",
        "                continue\n",
        "            \n",
        "            # Clean HTML summaries\n",
        "            current_clean = clean_html(record['current_summary'])\n",
        "            advanced_clean = clean_html(record['advanced_summary'])\n",
        "            \n",
        "            # Apply preference logic\n",
        "            if record['user_preference'] == 'A':\n",
        "                preferred_output = current_clean\n",
        "                non_preferred_output = advanced_clean\n",
        "            elif record['user_preference'] == 'B':\n",
        "                preferred_output = advanced_clean\n",
        "                non_preferred_output = current_clean\n",
        "            else:\n",
        "                errors.append(f\"Record {i}: Invalid preference\")\n",
        "                continue\n",
        "            \n",
        "            # Create DPO training record\n",
        "            dpo_record = {\n",
        "                'uuid': str(uuid.uuid4()),\n",
        "                'input_message': article_content,\n",
        "                'preferred_output': preferred_output,\n",
        "                'non_preferred_output': non_preferred_output\n",
        "            }\n",
        "            \n",
        "            transformed_records.append(dpo_record)\n",
        "            \n",
        "        except Exception as e:\n",
        "            errors.append(f\"Record {i}: {str(e)}\")\n",
        "            continue\n",
        "    \n",
        "    print(f\"‚úÖ Transformed {len(transformed_records)} records successfully\")\n",
        "    if errors:\n",
        "        print(f\"‚ö†Ô∏è {len(errors)} records failed transformation:\")\n",
        "        for error in errors[:5]:  # Show first 5 errors\n",
        "            print(f\"  {error}\")\n",
        "        if len(errors) > 5:\n",
        "            print(f\"  ... and {len(errors) - 5} more errors\")\n",
        "    \n",
        "    return transformed_records\n",
        "\n",
        "# Transform the data\n",
        "if feedback_data:\n",
        "    print(\"üîÑ Transforming feedback data...\")\n",
        "    dpo_records = transform_feedback_data(feedback_data)\n",
        "    \n",
        "    # Show sample transformed record\n",
        "    if dpo_records:\n",
        "        print(f\"\\nüìù Sample transformed record:\")\n",
        "        sample = dpo_records[0]\n",
        "        for key, value in sample.items():\n",
        "            if key == 'input_message':\n",
        "                print(f\"  {key}: {value[:100]}... (length: {len(value)})\")\n",
        "            else:\n",
        "                print(f\"  {key}: {value[:100]}{'...' if len(value) > 100 else ''}\")\n",
        "else:\n",
        "    print(\"‚ùå No data to transform\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Load Data into DPO Training Table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Loading DPO training data...\n",
            "üì§ Loading batch 1/1 (46 records)...\n",
            "‚úÖ Batch 1 loaded successfully\n",
            "\n",
            "üìä Load Summary:\n",
            "  ‚úÖ Successfully loaded: 46 records\n",
            "  ‚ùå Failed: 0 batches\n",
            "\n",
            "üéâ ETL Pipeline Complete!\n",
            "‚úÖ 46 records ready for DPO fine-tuning\n",
            "üìä Total records in dpo_training_data table: 1\n"
          ]
        }
      ],
      "source": [
        "# Load transformed data into dpo_training_data table\n",
        "def load_dpo_data(dpo_records, batch_size=50):\n",
        "    \"\"\"\n",
        "    Load DPO training records into the database\n",
        "    \n",
        "    Args:\n",
        "        dpo_records: List of transformed DPO records\n",
        "        batch_size: Number of records to insert per batch\n",
        "    \n",
        "    Returns:\n",
        "        Success count and error details\n",
        "    \"\"\"\n",
        "    if not dpo_records:\n",
        "        print(\"‚ùå No records to load\")\n",
        "        return 0, []\n",
        "    \n",
        "    success_count = 0\n",
        "    errors = []\n",
        "    \n",
        "    # Process in batches\n",
        "    for i in range(0, len(dpo_records), batch_size):\n",
        "        batch = dpo_records[i:i + batch_size]\n",
        "        batch_num = (i // batch_size) + 1\n",
        "        total_batches = (len(dpo_records) + batch_size - 1) // batch_size\n",
        "        \n",
        "        print(f\"üì§ Loading batch {batch_num}/{total_batches} ({len(batch)} records)...\")\n",
        "        \n",
        "        try:\n",
        "            # Insert batch\n",
        "            response = supabase.table('dpo_training_data').insert(batch).execute()\n",
        "            \n",
        "            if response.data:\n",
        "                success_count += len(batch)\n",
        "                print(f\"‚úÖ Batch {batch_num} loaded successfully\")\n",
        "            else:\n",
        "                errors.append(f\"Batch {batch_num}: No data returned from insert\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            error_msg = f\"Batch {batch_num}: {str(e)}\"\n",
        "            errors.append(error_msg)\n",
        "            print(f\"‚ùå {error_msg}\")\n",
        "    \n",
        "    print(f\"\\nüìä Load Summary:\")\n",
        "    print(f\"  ‚úÖ Successfully loaded: {success_count} records\")\n",
        "    print(f\"  ‚ùå Failed: {len(errors)} batches\")\n",
        "    \n",
        "    if errors:\n",
        "        print(f\"  ‚ö†Ô∏è Errors:\")\n",
        "        for error in errors:\n",
        "            print(f\"    {error}\")\n",
        "    \n",
        "    return success_count, errors\n",
        "\n",
        "# Load the data\n",
        "if 'dpo_records' in locals() and dpo_records:\n",
        "    print(\"üöÄ Loading DPO training data...\")\n",
        "    success_count, load_errors = load_dpo_data(dpo_records)\n",
        "    \n",
        "    if success_count > 0:\n",
        "        print(f\"\\nüéâ ETL Pipeline Complete!\")\n",
        "        print(f\"‚úÖ {success_count} records ready for DPO fine-tuning\")\n",
        "        \n",
        "        # Verify the data was loaded\n",
        "        try:\n",
        "            verify_response = supabase.table('dpo_training_data').select('count').execute()\n",
        "            print(f\"üìä Total records in dpo_training_data table: {len(verify_response.data)}\")\n",
        "        except:\n",
        "            print(\"üìä Verification query failed, but data was loaded\")\n",
        "    else:\n",
        "        print(\"‚ùå No data was loaded successfully\")\n",
        "else:\n",
        "    print(\"‚ùå No transformed data available to load\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Complete ETL Pipeline Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ready to run the complete ETL pipeline!\n",
            "Execute: run_complete_etl()\n",
            "\n",
            "Or run individual steps:\n",
            "- extract_feedback_data()\n",
            "- transform_feedback_data(feedback_data)\n",
            "- load_dpo_data(dpo_records)\n"
          ]
        }
      ],
      "source": [
        "# Complete ETL pipeline function\n",
        "def run_complete_etl():\n",
        "    \"\"\"\n",
        "    Run the complete ETL pipeline from start to finish\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with pipeline results\n",
        "    \"\"\"\n",
        "    print(\"üöÄ Starting Complete ETL Pipeline\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    results = {\n",
        "        'extracted': 0,\n",
        "        'transformed': 0,\n",
        "        'loaded': 0,\n",
        "        'errors': []\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        # Step 1: Extract\n",
        "        print(\"\\nüìä Step 1: Extracting data...\")\n",
        "        feedback_data = extract_feedback_data()\n",
        "        results['extracted'] = len(feedback_data)\n",
        "        \n",
        "        if not feedback_data:\n",
        "            results['errors'].append(\"No data extracted\")\n",
        "            return results\n",
        "        \n",
        "        # Step 2: Transform\n",
        "        print(\"\\nüîÑ Step 2: Transforming data...\")\n",
        "        dpo_records = transform_feedback_data(feedback_data)\n",
        "        results['transformed'] = len(dpo_records)\n",
        "        \n",
        "        if not dpo_records:\n",
        "            results['errors'].append(\"No data transformed\")\n",
        "            return results\n",
        "        \n",
        "        # Step 3: Load\n",
        "        print(\"\\nüì§ Step 3: Loading data...\")\n",
        "        success_count, load_errors = load_dpo_data(dpo_records)\n",
        "        results['loaded'] = success_count\n",
        "        results['errors'].extend(load_errors)\n",
        "        \n",
        "        print(f\"\\nüéâ ETL Pipeline Complete!\")\n",
        "        print(f\"‚úÖ Extracted: {results['extracted']} records\")\n",
        "        print(f\"‚úÖ Transformed: {results['transformed']} records\")\n",
        "        print(f\"‚úÖ Loaded: {results['loaded']} records\")\n",
        "        \n",
        "        if results['errors']:\n",
        "            print(f\"‚ö†Ô∏è Errors: {len(results['errors'])}\")\n",
        "        \n",
        "        return results\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = f\"Pipeline failed: {str(e)}\"\n",
        "        results['errors'].append(error_msg)\n",
        "        print(f\"‚ùå {error_msg}\")\n",
        "        return results\n",
        "\n",
        "# Run the complete pipeline\n",
        "print(\"Ready to run the complete ETL pipeline!\")\n",
        "print(\"Execute: run_complete_etl()\")\n",
        "print(\"\\nOr run individual steps:\")\n",
        "print(\"- extract_feedback_data()\")\n",
        "print(\"- transform_feedback_data(feedback_data)\")\n",
        "print(\"- load_dpo_data(dpo_records)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
